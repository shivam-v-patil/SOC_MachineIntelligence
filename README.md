# SOC_MachineIntelligence
#Checkpoint 1
  <P>We started our project with basic installation and setup of Python and Jupyter notebook in week 1. Then we learnt about the data types, variables, and basic operators in python. Video lectures, as well as reading material, were shared with us. Then we learnt about python data structures like Lists, Tuples, Sets, Dictionary, and Arrays. After that, we started with conditions, loops, Functions, Objects & Classes. We were given a notebook to get familiar with all the basic stuff in python. In short in the first week spent our time getting acquainted with Python to do basic operations.</P>
    <P>In week 2, we were introduced to an important package NumPy. We learnt about operations on NumPy arrays to ease our work. Then we move on to multi-dimensional NumPy arrays. Then we got brief information about different libraries in NumPy and some useful functions in each library. After that, we learnt about Git and GitHub fundamentals like how to make a repository, Master and new branches, Git’s workflow, remote repository, etc. Then we move on to Neural Networks basics. We learnt about neurons, layers, weights, biases, sigmoid function, and ReLU function. We were introduced to terms like cost function, gradient descent, backpropagation, Supervised learning, binary classification, notations in neural networks Activation Functions, Non-Linear Activations, etc in NN programming. In a nutshell, we learnt NumPy, Git, and GitHub and started with Neural networks in week 2.</P>
      <P>We combined the week 3 and week 4 content to learn more about Neural networks. We covered concepts that were introduced in week 2 in more detail with keeping the NN programming component in mind. We learnt many concepts in NN programming in continuation to week 2 like backpropagation, weight initialization, deep networks, forward and backward propagation in deep networks, Parameters, Hyperparameters, Dropout Regularization, data augmentation, early stopping, normalizing inputs and it’s needs,Vanishing/Exploding Gradients,Mini Batch Gradient Descent, Softmax Classification Function, etc. After that, we learnt about Tensorflow, Convolution Neural Networks (CNN), and Recurrent Neural Networks (RNN). We installed tensorflow2.0 in Anaconda. Then we learn about the basics of CNN and RNN and how they work. In short we continued learning about Neural Networks programming, tensorflow, CNN and RNN in week 3 and week4.</P>  
